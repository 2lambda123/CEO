% -*- mode: Noweb; noweb-code-mode: c-mode -*-
The iterativeSolvers structure is written in the header:
<<iterativeSolvers.h>>=
#ifndef __ITERATIVESOLVERS_H__
#define __ITERATIVESOLVERS_H__

#ifndef __CEO_H__
#include "ceo.h"
#endif

#ifndef __BTBT_H__
#include "BTBT.h"
#endif

#define MINRES_DEBUG

struct iterativeSolvers {

  <<parameters>>

  void cg_setup(int n_vector);

  void minres_setup(int n_vector);

  void cleanup(void);

  void cg(float *x, BTBT* A, float *b, int max_it, float* x0);

  void minres(float *x, BTBT* A, float *b, int max_it, float* x0);

  //  void info(void);
};
#endif // __ITERATIVESOLVERS_H__
@ The routines are expanded in the source:
<<iterativeSolvers.cu>>=
#include "iterativeSolvers.h"

<<CG setup>>

<<MINRES setup>>

<<cleanup>>

<<conjugate gradient>>

<<MINRES>>

@
The iterativeSolvers structure gather several routines implementing iterative methods to solve the linear system: $Ax=b$.
The setup method is allocated the required memory depending of the iterative method type:
\begin{description}
\item[CG] 
<<CG setup>>=
void iterativeSolvers::cg_setup(int n_vector)
{
  printf("\n@(CEO)>iterativeSolvers: CONJUGATE GRADIENT\n");
  N = n_vector;
  HANDLE_ERROR( cudaMalloc((void**)&d__vectors, sizeof(float)*N*4 ) );
  q = d__vectors;
  x = d__vectors + N;
  r = d__vectors + 2*N;
  p = d__vectors + 3*N;
  cublasCreate(&handle);
}
@  \item[minres] 
<<MINRES setup>>=
void iterativeSolvers::minres_setup(int n_vector)
{
  printf("\n@(CEO)>iterativeSolvers: MINRES\n");
  N = n_vector;
  HANDLE_ERROR( cudaMalloc((void**)&d__vectors, sizeof(float)*N*6 ) );
  nu_i   = d__vectors;
  nu_im1 = d__vectors + N;
  nu_ip1 = d__vectors + 2*N;
  w_i    = d__vectors + 3*N;
  w_im1  = d__vectors + 4*N;
  w_im2  = d__vectors + 5*N;
  cublasCreate(&handle);
}
@ \end{description}
@ 
The structure parameters are
<<parameters>>=
float *d__vectors,
  *q, *x, *r, *p,
  *nu_i, *nu_im1, *nu_ip1,
  *w_i, *w_im1, *w_im2;
int N;
cublasHandle_t handle;
cublasStatus_t status;
@
Memory is freed with
<<cleanup>>= 
void iterativeSolvers::cleanup(void)
{
  printf("\n@(CEO)>iterativeSolvers: freeing memory!\n");
  HANDLE_ERROR( cudaFree( d__vectors ) );
  cublasDestroy(handle);
}
@ 
The next routine implements the conjugate gradient iterative method:
<<conjugate gradient>>=
  void iterativeSolvers::cg(float *x, BTBT* A, float *b, int max_it, float* x0)
{
  float alpha, beta, gamma;
  int k;
  <<conjugate gradient init>>
  for (k=0;k<max_it;k++) {
    printf("CG IT=%d - ",k);
    <<conjugate gradient loop part 1>>
      if (k<(max_it-1)) {
	  <<conjugate gradient loop part 2>>
      }
  }    
}
@ 
The conjugate gradient algorithm is written:
\begin{itemize}
\item initialization:
  \begin{enumerate}
  \item $r=Ax_0$
<<conjugate gradient init>>=
    A->MVM(r , x0);
@ \item $r_0 = b - r_0$
<<conjugate gradient init>>=
beta = -1;
cublasSscal(handle, N, &beta, r, 1);
alpha = 1;
cublasSaxpy(handle, N, &alpha, b, 1, r, 1);
@ \item $p_0=r_0$
<<conjugate gradient init>>=
cublasScopy(handle, N, r, 1, p, 1);
@ \end{enumerate}
\item loop:
  \begin{enumerate}
  \item $q=Ap_k$
<<conjugate gradient loop part 1>>=
    A->MVM(q , p);
@ \item $\gamma=r_k^Tr_k$
<<conjugate gradient loop part 1>>=
cublasSdot(handle, N, r, 1, r, 1, &gamma);
printf("r norm=%6.2E\n",sqrt(gamma));
if (gamma==0) break;
@ \item $\alpha_k = {\displaystyle \gamma\over p_K^Tq}$
<<conjugate gradient loop part 1>>=
cublasSdot(handle, N, p, 1, q, 1, &alpha);
alpha = gamma/alpha;
@ \item $x_{k+1} = x_k + \alpha_kp_k$
<<conjugate gradient loop part 1>>=
cublasSaxpy(handle, N, &alpha, p, 1, x, 1);
@ \item $r_{k+1} = r_k - \alpha_kq$
<<conjugate gradient loop part 2>>=
alpha = -alpha;
cublasSaxpy(handle, N, &alpha, q, 1, r, 1);
@ \item $\beta_k = {\displaystyle r_{k+1}^Tr_{k+1} \over \gamma} $
<<conjugate gradient loop part 2>>=
cublasSdot(handle, N, r, 1, r, 1, &beta);
beta = beta/gamma;
@ \item $p_{k+1} = r_{k+1} + \beta_k p_k$
<<conjugate gradient loop part 2>>=
cublasSscal(handle, N, &beta, p, 1);
alpha = 1;
cublasSaxpy(handle, N, &alpha, r, 1, p, 1);
@  \end{enumerate}
 \end{itemize}

The MINRES iterative solver method is implemented in the next routine:
<<MINRES>>=
  void iterativeSolvers::minres(float *x, BTBT* A, float *b, int max_it, float* x0)
{
  float alpha, beta, gamma_i, gamma_im1, sigma_i, sigma_im1,
  eta, delta, rho1, rho2, rho3, nrm_r;
  int k;
  <<MINRES init>>
  for (k=0;k<max_it;k++) {
    printf("MINRES IT=%d - ",k);
    <<MINRES loop>>
  }    
}
@ 
The MINRES algorithm is written:
\begin{itemize}
\item initialization:
  \begin{enumerate}
  \item $r=Ax_0$
<<MINRES init>>=
A->MVM(nu_i , x0);
@ \item $r_0 = b - r_0$
<<MINRES init>>=
beta = -1;
cublasSscal(handle, N, &beta, nu_i, 1);
alpha = 1;
cublasSaxpy(handle, N, &alpha, b, 1, nu_i, 1);
cublasSnrm2(handle, N, b, 1, &beta);
#ifdef MINRES_DEBUG
printf("beta=%.2E\n",beta);
#endif
@ \item $\beta_1=\left\| \nu_1 \right\|_2$
<<MINRES init>>=
cublasSnrm2(handle, N, nu_i, 1, &beta);
nrm_r = beta;
#ifdef MINRES_DEBUG
printf("beta=%.2E\n",beta);
#endif
@ \item $\eta=beta_1$, $\gamma_1=\gamma_0=1$, $\sigma_1=\sigma_0=0$, $\nu_0=0$
<<MINRES init>>=
eta = beta;
gamma_i = gamma_im1 = 1;
sigma_i = sigma_im1 = 0;
@ \item $\nu_0=0$, $w_0=w_{-1}=0$
<<MINRES init>>=
HANDLE_ERROR( cudaMemset(nu_im1, 0, sizeof(float)*N ) );
HANDLE_ERROR( cudaMemset(w_im1 , 0, sizeof(float)*N ) );
HANDLE_ERROR( cudaMemset(w_im2 , 0, sizeof(float)*N ) );
@ \end{enumerate}
\item loop:
  \begin{enumerate}
  \item $\nu_i = \nu_i / \beta_i$
<<MINRES loop>>=
rho1 = 1/beta;
cublasSscal(handle, N, &rho1, nu_i, 1);
@ \item $\nu_{i+1}= A\nu_i$
<<MINRES loop>>=
A->MVM(nu_ip1 , nu_i);
@ \item $\alpha_i = \nu_i^T\nu_{i+1}$
<<MINRES loop>>=
cublasSdot(handle, N, nu_i, 1, nu_ip1, 1, &alpha);
#ifdef MINRES_DEBUG
printf("alpha=%.2E\n",alpha);
#endif
@ \item $\nu_{i+1} = \nu_{i+1} - \alpha_i\nu_i - \beta_i\nu_{i-1}$
<<MINRES loop>>=
alpha = -alpha;
beta  = -beta;
cublasSaxpy(handle, N, &alpha, nu_i, 1, nu_ip1, 1);
cublasSaxpy(handle, N, &beta, nu_im1, 1, nu_ip1, 1);
alpha = -alpha;
beta  = -beta;
@ \item $\delta = \gamma_i\alpha_i - \gamma_{i-1}\sigma_i\beta_i$
<<MINRES loop>>=
delta = gamma_i*alpha - gamma_im1*sigma_i*beta;
#ifdef MINRES_DEBUG
printf("delta=%.2E\n",delta);
#endif
@ \item $\rho_2 = \sigma_i\alpha_i + \gamma_{i-1}\gamma_i\beta_i$
<<MINRES loop>>=
rho2 = sigma_i*alpha + gamma_im1*gamma_i*beta;
#ifdef MINRES_DEBUG
printf("rho2=%.2E\n",rho2);
#endif
@ \item $\rho_3 = \sigma_{i-1}\beta_i$
<<MINRES loop>>=
rho3 = sigma_im1*beta;
#ifdef MINRES_DEBUG
printf("rho3=%.2E\n",rho3);
#endif
@ \item $\beta_{i+1}=\left\| \nu_{i+1} \right\|_2$
<<MINRES loop>>=
cublasSnrm2(handle, N, nu_ip1, 1, &beta);
#ifdef MINRES_DEBUG
printf("beta=%.2E\n",beta);
#endif
@ \item $\rho_1 = \sqrt{\delta^2+\beta_{i+1}^2}$
<<MINRES loop>>=
rho1 = hypotf(delta,beta);
#ifdef MINRES_DEBUG
printf("rho1=%.2E\n",rho1);
#endif
@ \item $\gamma_{i+1} = \delta / \rho_1$
<<MINRES loop>>=
gamma_im1 = gamma_i;
gamma_i = delta/rho1;
#ifdef MINRES_DEBUG
printf("gamma_im1=%.2E\n",gamma_im1);
printf("gamma_i=%.2E\n",gamma_i);
#endif
@ \item $\sigma_{i+1} = \beta_{i+1} / \rho_1$
<<MINRES loop>>=
sigma_im1 = sigma_i;
sigma_i = beta/rho1;
#ifdef MINRES_DEBUG
printf("sigma_im1=%.2E\n",sigma_im1);
printf("sigma_i=%.2E\n",sigma_i);
#endif
@ \item $w_i = (\nu_i-\rho_3w_{i-2}-\rho_2w_{i-1})/\rho_1$
<<MINRES loop>>=
cublasScopy(handle, N, nu_i, 1, w_i, 1);
rho1 = 1.0/rho1;
cublasSscal(handle, N, &rho1, w_i, 1);
rho3 = -rho3*rho1;
cublasSaxpy(handle, N, &rho3, w_im2, 1, w_i, 1);
rho2 = -rho2*rho1;
cublasSaxpy(handle, N, &rho2, w_im1, 1, w_i, 1);
@ \item $x_i = x_{i-1} + \gamma_{i+1}\eta w_i$
<<MINRES loop>>=
rho1 = gamma_i*eta;
cublasSaxpy(handle, N, &rho1, w_i, 1, x, 1);
@ \item $\left\| r_i \right\|_2 = \left| \sigma_{i+1} \right|\left\| r_{i-1} \right\|_2 $
<<MINRES loop>>=
nrm_r = nrm_r*fabs(sigma_i);
printf("r norm=%6.2E\n",nrm_r);
@ \item $\eta = \sigma_{i+1}\eta$
<<MINRES loop>>=
eta = -sigma_i*eta;
#ifdef MINRES_DEBUG
printf("eta=%.2E\n",eta);
#endif
@ \item
\begin{eqnarray}
  \label{eq:1}
  \nu_{i-1} &\leftarrow& \nu_i \nonumber\\
  \nu_{i} &\leftarrow& \nu_{i+1} \nonumber\\
  w_{i-2} &\leftarrow& w_{i-1} \nonumber\\
  w_{i-1} &\leftarrow& \nu_{i} \nonumber
\end{eqnarray}
<<MINRES loop>>=
cublasScopy(handle, N, nu_i  , 1, nu_im1, 1);
cublasScopy(handle, N, nu_ip1, 1, nu_i  , 1);
cublasScopy(handle, N, w_im1 , 1, w_im2 , 1);
cublasScopy(handle, N, w_i   , 1, w_im1 , 1);
if (beta==0) break;
@  \end{enumerate}
 \end{itemize}


The test routine is:
<<iterativeSolvers.bin>>=
#ifndef __CEO_H__
#include "ceo.h"
#endif
#ifndef __SOURCE_H__
#include "source.h"
#endif
#ifndef __ATMOSPHERE_H__
#include "atmosphere.h"
#endif
#ifndef __IMAGING_H__
#include "imaging.h"
#endif
#ifndef __CENTROIDING_H__
#include "centroiding.h"
#endif
#ifndef __AASTATS_H__
#include "aaStats.h"
#endif
#ifndef __BTBT_H__
#include "BTBT.h"
#endif
#include "iterativeSolvers.h"

   //#define N 10

   <<PA input>>

__global__ void fill(float *data, int n_data, float value)
{
  int k = blockIdx.x * blockDim.x + threadIdx.x;
  if (k<n_data)
    data[k] = value;
}

// Solving Ax=b
int main( void) {

  
<<complete test>>
}
@
In the following a simple test is performed:
<<simple test I>>=
/*
  The test requires to replace the MVM with MVM (Test 1) 
  in the code chunk BTBT.cu in the file BTBT.nw
*/
float *d__x, *d__b;
HANDLE_ERROR( cudaMalloc((void**)&d__x, sizeof(float)*N ) );
HANDLE_ERROR( cudaMemset(d__x, 0, sizeof(float)*N ) );
HANDLE_ERROR( cudaMalloc((void**)&d__b, sizeof(float)*N ) );
float b[N] = {1,2,3,4,5,6,7,8,9,10};
HANDLE_ERROR( cudaMemcpy( d__b, b, N*sizeof(float), cudaMemcpyHostToDevice) );

BTBT A;
A.setup(N);

iterativeSolvers iSolve;
/* iSolve.cg_setup(N); */
/* iSolve.cg(d__x, &A, d__b, 5, d__x); */
iSolve.minres_setup(N);
iSolve.minres(d__x, &A, d__b, 5, d__x);
iSolve.cleanup();

float *x;
x = (float *)malloc(sizeof(float)*N);
HANDLE_ERROR( cudaMemcpy( x, d__x, N*sizeof(float), cudaMemcpyDeviceToHost) );

for (int k=0;k<N;k++)
  printf("(%d) %5.1f\n",k,x[k]);

HANDLE_ERROR( cudaFree( d__x ) );
HANDLE_ERROR( cudaFree( d__b ) );
free(x);
@ 
<<simple test II>>=
/*
  The test requires to replace the MVM with MVM (Test 2) 
  in the code chunk BTBT.cu in the file BTBT.nw
*/
float *x;
x = (float *)malloc(sizeof(float)*N);
float *d__x, *d__b;
HANDLE_ERROR( cudaMalloc((void**)&d__x, sizeof(float)*N ) );
HANDLE_ERROR( cudaMalloc((void**)&d__b, sizeof(float)*N ) );

for (int k=0;k<N;k++) {
  x[k] = 1.0 + (float)rand();
  printf("(%d) %.3E\n",k,x[k]);
 }
HANDLE_ERROR( cudaMemcpy( d__b, x, N*sizeof(float), cudaMemcpyHostToDevice ) );

BTBT A;
A.setup(N);
/* A.MVM(d__b,d__x); */
/* HANDLE_ERROR( cudaMemcpy( x, d__b, N*sizeof(float), cudaMemcpyDeviceToHost) ); */

/* for (int k=0;k<N;k++) */
/*   printf("(%d) %5.1f\n",k,x[k]); */

fill LLL (1+N/16),16 RRR (d__x, N, 0);

iterativeSolvers iSolve;
/* iSolve.cg_setup(N); */
/* iSolve.cg(d__x, &A, d__b, 5, d__x); */
iSolve.minres_setup(N);
iSolve.minres(d__x, &A, d__b, 5, d__x);
iSolve.cleanup();

HANDLE_ERROR( cudaMemcpy( x, d__x, N*sizeof(float), cudaMemcpyDeviceToHost) );

for (int k=0;k<N;k++)
  printf("(%d) %5.1f\n",k,x[k]);

HANDLE_ERROR( cudaFree( d__x ) );
HANDLE_ERROR( cudaFree( d__b ) );
free(x);
@ 
A more complete test:
<<complete test>>=
int N = _N_LENSLET_*2, NP, PS_N_PX, PS_E_N_PX, i, j ,k, osf;
float *d__x, *d__b, *b, *d__ce, *d__phase_est, *phase_screen_est, *x;
float D, d, delta, delta_e, wf_rms, phase2nm, slopes2Angle, cxy0;
int *idx, *d__idx;

D = 0.4;
d = D/N_SIDE_LENSLET;
delta = d/_N_PX_PUPIL_;
osf = 2;
delta_e = d/osf;

NP = osf*N_SIDE_LENSLET+1;
PS_E_N_PX = NP;
PS_E_N_PX *= PS_E_N_PX;
PS_N_PX = N_SIDE_LENSLET*_N_PX_PUPIL_;

printf("\nd    =%.4f\n",d);
printf("\ndelta=%.4f\n",delta);
printf("\ndelta_e=%.4f\n",delta_e);

source src, *d__src;
atmosphere atm;
imaging lenslet_array;
centroiding cog;
aaStats aa;
BTBT aaCov;
paStats pa;
BTBT paCov;
iterativeSolvers iSolve;
stats S;
S.setup();
stopwatch tid;

src.setup(ARCSEC(0) , 0, INFINITY);
HANDLE_ERROR( cudaMalloc( (void**)&d__src, sizeof(source)*_N_SOURCE_ ) );
HANDLE_ERROR( cudaMemcpy( d__src, &src,
			  sizeof(source)*_N_SOURCE_ ,
			  cudaMemcpyHostToDevice ) );
        
// Single layer turbulence profile
float altitude[] = {0},
  xi0[] = {1},
  wind_speed[] = {10},
  wind_direction[] = {0};
// Atmosphere
atm.setup(0.15,30,altitude,xi0,wind_speed,wind_direction);
//atm.reset();

phase2nm = 1E9*atm.wavelength/2/PI;
slopes2Angle = (atm.wavelength/2/d);

// SH WFS
lenslet_array.setup();

// Centroid
cog.setup();

// covariances
aa.setup(N_SIDE_LENSLET,&atm,d);
aaCov.setup(2,2,N_SIDE_LENSLET,aa.d__cov);

pa.setup(N_SIDE_LENSLET,osf,&atm,d);
paCov.setup(1,2,NP,pa.d__cov);

// CG
iSolve.minres_setup(N);
//iSolve.minres_setup(N);

atm.get_phase_screen(delta,PS_N_PX,delta,PS_N_PX,d__src,0);

wf_rms = phase2nm*S.std(d__src->phase, _N_PIXEL_);
printf("\n WF RMS: %7.2fnm\n",wf_rms);

float phase_screen[_N_PIXEL_];
HANDLE_ERROR( cudaMemcpy( phase_screen, d__src->phase,
			  sizeof(float)*_N_PIXEL_,
			  cudaMemcpyDeviceToHost ) );
FILE *fid;
fid = fopen("phaseScreen.bin","wb");
fwrite(phase_screen,sizeof(float),_N_PIXEL_,fid);
fclose(fid);

float *d__phase_screen_low_res;
HANDLE_ERROR( cudaMalloc( (void**)&d__phase_screen_low_res, sizeof(float)*PS_E_N_PX ) );
atm.get_phase_screen(d__phase_screen_low_res,delta_e,NP,delta_e,NP,d__src,0);

float *phase_screen_low_res;
phase_screen_low_res = (float*)malloc(sizeof(float)*PS_E_N_PX);
HANDLE_ERROR( cudaMemcpy( phase_screen_low_res, d__phase_screen_low_res,
			  sizeof(float)*PS_E_N_PX,
			  cudaMemcpyDeviceToHost ) );
fid = fopen("phaseScreenLowRes.bin","wb");
fwrite(phase_screen_low_res,sizeof(float),PS_E_N_PX,fid);
fclose(fid);

<<wavefront sensing>>

<<linear solver (prep.)>>
<<MVM (prep.)>>

char filename[100];
for (k=1;k<6;k++) {

  sprintf(filename,"MINRES_phaseEst_%d.bin",k);
HANDLE_ERROR( cudaMemset(d__x, 0, sizeof(float)*N ) );

tid.tic();

iSolve.minres(d__x, &aaCov, d__b, k, d__x);

HANDLE_ERROR( cudaMemcpy( x, d__x, sizeof(float)*N, cudaMemcpyDeviceToHost ) );
printf("\nx=\n");
for (int kk=0;kk<N;kk++)
  printf(" (%2d) %+.2E\n",kk,x[kk]);

<<MVM>>

tid.toc("WAVEFRONT ESTIMATION");

<<MVM (wrap.)>>

}

HANDLE_ERROR( cudaFree( d__src) );
atm.cleanup();
lenslet_array.cleanup();
cog.cleanup();
aa.cleanup();
pa.cleanup();
aaCov.cleanup();
paCov.cleanup();
iSolve.cleanup();
S.cleanup();
HANDLE_ERROR( cudaFree( d__x ) );
HANDLE_ERROR( cudaFree( d__b ) );
HANDLE_ERROR( cudaFree( d__idx ) );
HANDLE_ERROR( cudaFree( d__ce ) );
HANDLE_ERROR( cudaFree( d__phase_est ) );
HANDLE_ERROR( cudaFree( d__phase_screen_low_res ) );
free(phase_screen_low_res);
free(b);
free(idx);
free(phase_screen_est);
free(x);
@ 
<<PA input>>=
__global__ void set_pa_input(float *pa_c, float *aa_c, int *idx, int N) 
{
  int i, j, k;
  i = blockIdx.x * blockDim.x + threadIdx.x;
  j = blockIdx.y * blockDim.y + threadIdx.y;
  if ( (i<N) && (j<N) ) {
    k = i*N + j;
    pa_c[idx[k]] = aa_c[k];
  }
}
@ 
<<wavefront sensing>>=
lenslet_array.propagate(d__src);
cxy0 = (_N_PX_PUPIL_ - 1)/2.0;
cog.get_data(lenslet_array.d__frame, cxy0, cxy0, slopes2Angle);
HANDLE_ERROR( cudaMalloc((void**)&d__b, sizeof(float)*N ) );
HANDLE_ERROR( cudaMemcpy( d__b              , cog.d__cx,  
			  _N_LENSLET_*sizeof(float), cudaMemcpyDeviceToDevice) );
HANDLE_ERROR( cudaMemcpy( d__b + _N_LENSLET_, cog.d__cy,  
			  _N_LENSLET_*sizeof(float), cudaMemcpyDeviceToDevice) );
b = (float *)malloc(sizeof(float)*N);
HANDLE_ERROR( cudaMemcpy( b, d__b,
			  sizeof(float)*N,
			  cudaMemcpyDeviceToHost ) );
/* printf("\n   Cx       Cy\n"); */
/* for (k=0;k<_N_LENSLET_;k++) { */
/*   printf("%+6.4E  %+6.4E\n",b[k],b[k+_N_LENSLET_]); */
/* } */
fid = fopen("centroids.bin","wb");
fwrite(b,sizeof(float),N,fid);
fclose(fid);
@ 
<<linear solver (prep.)>>=
idx = (int *)malloc(sizeof(int)*_N_LENSLET_);
k = -1;
//printf("\n k   idx\n");
for (i=1;i<2*N_SIDE_LENSLET;i+=2) {
  for (j=1;j<2*N_SIDE_LENSLET;j+=2) {
    idx[++k] = i*(2*N_SIDE_LENSLET + 1) + j;
    //printf("(%2d) %2d\n",k,idx[k]);
  }
 }
HANDLE_ERROR( cudaMalloc( (void**)&d__idx, sizeof(int)*_N_LENSLET_ ) );
HANDLE_ERROR( cudaMemcpy( d__idx, idx,
			  sizeof(int)*_N_LENSLET_,
			  cudaMemcpyHostToDevice ) );

HANDLE_ERROR( cudaMalloc((void**)&d__x, sizeof(float)*N ) );
x = (float*)malloc(sizeof(float)*N);
@ 
<<linear solver (conjugate gradient)>>=
iSolve.cg(d__x, &aaCov, d__b, 5, d__x);
@ 
<<linear solver (MINRES)>>=
iSolve.minres(d__x, &aaCov, d__b, 5, d__x);
@ 
<<MVM (prep.)>>=
HANDLE_ERROR( cudaMalloc((void**)&d__ce, sizeof(float)*PS_E_N_PX*2 ) );
HANDLE_ERROR( cudaMemset(d__ce, 0, sizeof(float)*PS_E_N_PX*2 ) );
HANDLE_ERROR( cudaMalloc( (void**)&d__phase_est           , sizeof(float)*PS_E_N_PX ) );
dim3 blockDim(16,16);
dim3 gridDim(N_SIDE_LENSLET/16+1,N_SIDE_LENSLET/16+1);
@ 
<<MVM>>=
set_pa_input LLL gridDim,blockDim RRR (d__ce, d__x, d__idx, N_SIDE_LENSLET);
set_pa_input LLL gridDim,blockDim RRR (d__ce + PS_E_N_PX, d__x + _N_LENSLET_, d__idx, N_SIDE_LENSLET);
paCov.MVM(d__phase_est,d__ce);
@ 
<<MVM (wrap.)>>=
phase_screen_est     = (float*)malloc(sizeof(float)*PS_E_N_PX);
HANDLE_ERROR( cudaMemcpy( phase_screen_est, d__phase_est,
			  sizeof(float)*PS_E_N_PX,
			  cudaMemcpyDeviceToHost ) );
fid = fopen(filename,"wb");
//fid = fopen("phaseScreenEst.bin","wb");
fwrite(phase_screen_est,sizeof(float),PS_E_N_PX,fid);
fclose(fid);
